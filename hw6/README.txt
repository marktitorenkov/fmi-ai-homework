Реализирайте алгоритъма за класификационно дърво на решенията ID3 и го приложете върху данните breast-cancer.arff (https://archive.ics.uci.edu/ml/datasets/breast+cancer).

Някои от характеристиките съдържат стойността "?", която обозначава липсваща стойност. Решете задачата като запълните стойността с подход, който вие изберете и обосновете защо сте избрали. 

За избягване на преспецифициране (overfitting) на дървото използвайте по ваш избор поне един подход за предварително подрязване на дървото (pre-pruning) и поне един подход за последващо подрязване на дървото (post-pruning):

1. Предварително подрязване на дървото (pre-pruning):
Константа N дефинираща максимална дълбочина на дървото.
Константа K дефинираща минимален брой на обучаващи примери в множеството (за листо).
Константа G дефинираща минимална информационна печалба.
2. Последващо подрязване на дървото (post-pruning):
Оценка на грешката на модела при подрязване на дървото (Error Estimation или Reduced Error Pruning).
χ2 (ХИ-квадрат) тест (Chi2 test).
Подрязване с минимални разходи и сложност (Minimal Cost-Complexity Pruning)
Всеки допълнителен подход за подрязване на дървото ще бъде взет като бонус.

За тестване на алгоритъма разделете данните на тренировъчни и тестови множества в съотношение 80:20, като преди това ги разбъркате. Разделението трябва да бъде стратифицирано, за да се запази съотношението на класовете (201 без рецидив, 85 с рецидив) в новополучените тренировъчни и тестови множества.

Като вход приемете три възможни стойности - 0, 1 и 2:

0 означава да се използва само подход за предварително подрязване на дървото (pre-pruning).
1 означава да се използва само подход за последващо подрязване на дървото (post-pruning).
2 означава да се използват и двата типа подходи за подрязване на дървото.
Ако има повече от един тип варианти на подход за подрязване, те могат да бъдат указани със съответната буква след номера на подхода. Тоест ако имаме и трите варианта за предварително подрязване посочени горе, те ще бъдат кодирани съответно с буквите N, K и G. За последващото подрязване съответните букви са E, X и C. При вход "0", означава, че ще се приложат всички реализирани варианти на подхода за предварително подрязване. При вход "0 K" означава, че ще се приложи само варианта за минимален брой примери. За останалите комбинации логиката е същата.

Като изход изкарайте точността на модела върху тренировъчното множество (обучен и тестван на него), точността и стандартното отклонение на модела при приложена 10-кратна кръстосана проверка върху тренировъчното множество и точността на модела върху тестовото множество:

Точност (Accuracy) върху тренировъчното множество за стандартното разделение.
Средна точност (Average Accuracy) и стандартно отклонение за 10-кратната кръстосана проверка (10-fold cross-validation).
Точност (Accuracy) върху тестовото множество.
Примерен вход:
0

Примерен изход:
1. Train Set Accuracy:
    Accuracy: 70.90%

10-Fold Cross-Validation Results:
    Accuracy Fold 1: 71.00%
    Accuracy Fold 2: 69.72%
    Accuracy Fold 3: 71.30%
    Accuracy Fold 4: 73.05%
    Accuracy Fold 5: 69.53%
    Accuracy Fold 6: 69.53%
    Accuracy Fold 7: 73.16%
    Accuracy Fold 8: 71.53%
    Accuracy Fold 9: 69.06%
    Accuracy Fold 10: 71.09%

    Average Accuracy: 70.90%
    Standard Deviation: 1.37%

2. Test Set Accuracy:
    Accuracy: 69.07%

* При решението на задачата е разрешено да се използват структури от данни като DataFrame.

** Сравнете резултатите, които постигате с различните подходи за избягване на преспецифициране (overfitting).

*** Като бонус към задачата можете да се опитате да имплементирате алгоритъма Random Forest.
